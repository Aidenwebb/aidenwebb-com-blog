[{"content":"Cloud-init is the industry standard multi-distribution method for cross-platform cloud instance initialization. It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations.\nUsing Proxmox templates in tandem with Cloud-init streamlines the process of launching new VMs. With this approach, a template can rapidly generate a new VM, and Cloud-init takes care of the initial setup during boot, reducing your tasks to simply setting up the hostname and initial user account. This eliminates the need for manually configuring a fresh operating system installation for each VM. This guide focuses on creating a template Debian configuration.\nAlthough Debian doesn\u0026rsquo;t offer a dedicated image specifically for this scenario, the Debian images intended for OpenStack/Cloud are equipped with Cloud-init compatibility. For more information on how Proxmox supports Cloud-Init, refer to Proxmox\u0026rsquo;s documentation.\nAssuming you\u0026rsquo;re a beginner, running through this guide to get a template set up and configured should take you approximately 10 minutes. Diving a bit deeper in to each of the commands will take longer to understand what\u0026rsquo;s happening behind the scenes. It can be useful to have the Proxmox web interface open as you proceed through each step so you can see how the changes after each command are reflected in the web interfac.\nGood luck and happy hacking!\nDownload the Cloud-init image Download the latest genericcloud image from the Debian Official Cloud Images Repository directly on to the Proxmox host\nDebian 11 1 wget https://cloud.debian.org/images/cloud/bullseye/20231004-1523/debian-11-genericcloud-amd64-20231004-1523.qcow2 Debian 12 1 wget https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-genericcloud-amd64.qcow2 Create a new VM using the image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # Set the VM ID to operate on VMID=9001 # Choose a name for the VM TEMPLATE_NAME=Debian12CloudInit # Choose the disk image to import DISKIMAGE=debian-12-genericcloud-amd64.qcow2 # Select Host disk HOST_DISK=local-zfs # Create the VM qm create $VMID --name $TEMPLATE_NAME --net0 virtio,bridge=vmbr0 # Set the OSType to Linux Kernel 6.x qm set $VMID --ostype l26 # Import the disk qm importdisk $VMID $DISKIMAGE $HOST_DISK # Attach disk to scsi bus qm set $VMID --scsihw virtio-scsi-pci --scsi0 $HOST_DISK:vm-$VMID-disk-0 # Set scsi disk as boot device qm set $VMID --boot c --bootdisk scsi0 # Create and attach cloudinit drive qm set $VMID --ide2 $HOST_DISK:cloudinit # Set serial console, which is needed by OpenStack/Proxmox qm set $VMID --serial0 socket --vga serial0 # Enable Qemu Guest Agent qm set $VMID --agent enabled=1 # optional but recommened Configure other VM options to suite needs 1 2 # Start the VM at boot qm set $VMID --onboot 1 Convert the VM into a template 1 qm template $VMID Create a new VM from the template 1 2 3 4 # Set a variable for our new VM ID NEW_VMID=2001 NEW_VM_NAME=MyNewServer qm clone $VMID $NEW_VMID --name $NEW_VM_NAME --full Configure the VM Once the VM is created, there are some common adjustments we might want to make, such as assigning additional vCPUs, RAM, or disk space.\n1 2 3 4 5 6 7 8 9 10 11 12 # Show Current configs qm config $NEW_VMID # Allocate 2GB of RAM qm set $NEW_VMID --memory 2048 # Allocate 2 vCPU Cores qm set $NEW_VMID --cores 2 # Resize bootdisk ## Get bootdisk interface NEW_VM_BOOTDISK_INTERFACE=$(qm config $NEW_VMID | grep bootdisk | awk \u0026#39;{print $2}\u0026#39;) ## Resize bootdisk to 32GB qm disk resize $NEW_VMID $NEW_VM_BOOTDISK_INTERFACE 32G Configure Cloud-init 1 2 3 4 5 6 7 8 9 10 11 # Set Network config ## Static qm set $NEW_VMID --ipconfig0 ip=172.17.1.132/24,gw=172.17.1.1 ## DHCP qm set $NEW_VMID --ipconfig0 ip=dhcp # Set Username qm set $NEW_VMID --ciuser aiden # Setup public SSH keys (one key per line, OpenSSH format). qm set $NEW_VMID --sshkeys ~/vm_sshkeys/keylist Boot and initialise the VM 1 2 3 4 5 6 7 sudo apt update sudo apt upgrade # Install and enable QEMU guest agent sudo apt install qemu-guest-agent sudo systemctl enable qemu-guest-agent sudo systemctl start qemu-guest-agent References Proxmox PVE Documentation Cloud-init Github ","permalink":"https://www.aidenwebb.com/posts/create-a-debian-cloud-init-template-on-proxmox/","summary":"Cloud-init is the industry standard multi-distribution method for cross-platform cloud instance initialization. It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations.\nUsing Proxmox templates in tandem with Cloud-init streamlines the process of launching new VMs. With this approach, a template can rapidly generate a new VM, and Cloud-init takes care of the initial setup during boot, reducing your tasks to simply setting up the hostname and initial user account.","title":"Create a Debian Cloud-init Template on Proxmox"},{"content":"The Problem Microsofts latest update to Office 365 has changed the way \u0026ldquo;Share\u0026rdquo; function operates. Previously, when you clicked the \u0026ldquo;Share\u0026rdquo; button, you were presented with a list of options, including sharing a link, or attaching a copy of your document instead.\nNow, if the file you are working on is already saved in a shareable OneDrive or Sharepoint locationsync\u0026rsquo;d, the only option you are presented is to share a link to the document. The \u0026ldquo;Send a Copy\u0026rdquo; option is missing.\nThe Workaround The workaround is to pin the Send menu to your quick access toolbar, which will then give you access to the Send A Copy function again.\nHow to Pin the Send Menu Right click on the Quick Access Toolbar and select Customize Quick Access Toolbar In the left-hand column, select All Commands from the Choose commands from dropdown In the left-hand column, scroll down to the Send menu and select it. Click the Add button to add it to the Quick Access Toolbar Click OK to save the changes You should now see the Send menu in your Quick Access Toolbar ","permalink":"https://www.aidenwebb.com/posts/microsoft-office-send-a-file-as-an-attachment/","summary":"The Problem Microsofts latest update to Office 365 has changed the way \u0026ldquo;Share\u0026rdquo; function operates. Previously, when you clicked the \u0026ldquo;Share\u0026rdquo; button, you were presented with a list of options, including sharing a link, or attaching a copy of your document instead.\nNow, if the file you are working on is already saved in a shareable OneDrive or Sharepoint locationsync\u0026rsquo;d, the only option you are presented is to share a link to the document.","title":"Microsoft Office - Send a file as an Attachment"},{"content":"Here\u0026rsquo;s a streamlined guide on how to mount a qcow2 disk image on your host server/system, which can come in handy for tasks like resetting passwords, editing files, or recovering data without needing to run the virtual machine.\nStep 1 - Activating NBD on the Host In your terminal, run the following command to enable NBD (Network Block Device) on your host (with sudo if required):\n1 modprobe nbd max_part=8 Step 2 - Link the QCOW2 to Network Block Device Next, connect the QCOW2 disk image to the network block device using the following command:\n1 qemu-nbd --connect=/dev/nbd0 /var/lib/vz/images/100/vm-100-disk-1.qcow2 Step 3 - Identify the Virtual Machine Partitions You can find the partitions of the virtual machine by running the following command:\n1 fdisk /dev/nbd0 -l Step 4 - Access the Virtual Machine Partition Now, to mount the partition from the virtual machine, you can use the following command:\n1 mount /dev/nbd0p1 /mnt/my-mountpoint/ Step 5 - Wrapping Up: Unmount and Disconnect Once you\u0026rsquo;ve finished with the tasks, it\u0026rsquo;s crucial to unmount and disconnect appropriately. Use the following commands to do so:\n1 2 3 umount /mnt/somepoint/ qemu-nbd --disconnect /dev/nbd0 rmmod nbd This will effectively close off your session.\n","permalink":"https://www.aidenwebb.com/posts/how-to-mount-a-qcow2-disk-image/","summary":"Here\u0026rsquo;s a streamlined guide on how to mount a qcow2 disk image on your host server/system, which can come in handy for tasks like resetting passwords, editing files, or recovering data without needing to run the virtual machine.\nStep 1 - Activating NBD on the Host In your terminal, run the following command to enable NBD (Network Block Device) on your host (with sudo if required):\n1 modprobe nbd max_part=8 Step 2 - Link the QCOW2 to Network Block Device Next, connect the QCOW2 disk image to the network block device using the following command:","title":"How to Mount a qcow2 Disk Image"},{"content":"This guide covers installation of TP-Link\u0026rsquo;s Omada Software Controller on Debian 11.\nAt the time of writing, Omada Controller version is 5.9.31.\nUpdate and Upgrade system 1 apt update \u0026amp;\u0026amp; apt upgrade -y Install omada dependencies 1 apt install -y openjdk-11-jdk-headless curl autoconf make gcc Install MongoDB Go to Mongo DB\u0026rsquo;s repository and select an appropriate server version. I\u0026rsquo;m using MongoDb Server 4.4.16\n1 2 wget https://repo.mongodb.org/apt/debian/dists/buster/mongodb-org/4.4/main/binary-amd64/mongodb-org-server_4.4.16_amd64.deb apt install -y ./mongodb-org-server_4.4.16_amd64.deb Compile and install jsvc Go to Apache Commons Daemon repo and select an appropriate commons version. As of writing, the latest version is 1.3.3 so that\u0026rsquo;s what I\u0026rsquo;ll use.\n1 2 3 4 5 6 7 8 9 10 11 12 13 mkdir -p /opt/tplink-sources \u0026amp;\u0026amp; cd /opt/tplink-sources wget -c https://dlcdn.apache.org/commons/daemon/source/commons-daemon-1.3.3-src.tar.gz -O - | tar -xz cd commons-daemon-1.3.3-src/src/native/unix sh support/buildconf.sh ./configure --with-java=/usr/lib/jvm/java-11-openjdk-amd64 make ln -s /opt/tplink-sources/commons-daemon-1.3.3-src/src/native/unix/jsvc /usr/bin/ Download and install Omada Controller 1 2 3 cd /opt/tplink-sources wget https://static.tp-link.com/upload/software/2023/202303/20230321/Omada_SDN_Controller_v5.9.31_Linux_x64.deb dpkg --ignore-depends=jsvc -i ./Omada_SDN_Controller_v5.9.31_Linux_x64.deb ","permalink":"https://www.aidenwebb.com/posts/install-tplink-omada-on-debian-11/","summary":"This guide covers installation of TP-Link\u0026rsquo;s Omada Software Controller on Debian 11.\nAt the time of writing, Omada Controller version is 5.9.31.\nUpdate and Upgrade system 1 apt update \u0026amp;\u0026amp; apt upgrade -y Install omada dependencies 1 apt install -y openjdk-11-jdk-headless curl autoconf make gcc Install MongoDB Go to Mongo DB\u0026rsquo;s repository and select an appropriate server version. I\u0026rsquo;m using MongoDb Server 4.4.16\n1 2 wget https://repo.mongodb.org/apt/debian/dists/buster/mongodb-org/4.4/main/binary-amd64/mongodb-org-server_4.4.16_amd64.deb apt install -y .","title":"Install Tplink Omada on Debian 11"},{"content":"Yesterday Microsoft announced a new critical vulnerability CVE-2023-23397, a vulnerability in Microsoft Outlook that allows a threat actor to harvest NTLMv2 hashes via a specifically crafted Outlook appointment.\nMicrosoft state that attackers can exploit this vulnerability by sending an email that triggers automatically when it is retrieved and processed by the Outlook client. This can lead to exploitation BEFORE the email is viewed in the Preview Pane.\nThey also state that this vulnerability is being actively exploited in the wild.\nIn the interest of quickly checking and triggering patches on affected systems, the below Powershell oneliner will report the patch status and office version on the system it runs on, and if the system is unpatched, it will attempt to run the ClickToRun updater.\nPlease modify it as required to suite your needs and different office versions. This was written to target Microsoft 365 Apps on Current Channel.\n1 $env:computername ; Get-ItemProperty -Path \u0026#39;HKLM:\\SOFTWARE\\Microsoft\\Office\\ClickToRun\\Configuration\u0026#39; | Select-Object -ExpandProperty VersionToReport | %{if($_ -eq \u0026#34;16.0.16130.20306\u0026#34;){Write-Host -ForegroundColor Green \u0026#34;Patched - Office Version: $_\u0026#34;} else {Write-Host -ForegroundColor Red \u0026#34;Vulnerable - Office Version: $_\u0026#34;; Start-Process -FilePath \u0026#34;C:\\Program Files\\Common Files\\microsoft shared\\ClickToRun\\OfficeC2RClient.exe\u0026#34; -ArgumentList {/update user}}} And across multiple lines for readability:\n1 2 3 4 5 6 7 8 9 $env:computername Get-ItemProperty -Path \u0026#39;HKLM:\\SOFTWARE\\Microsoft\\Office\\ClickToRun\\Configuration\u0026#39; | Select-Object -ExpandProperty VersionToReport | %{ if($_ -eq \u0026#34;16.0.16130.20306\u0026#34;){ Write-Host -ForegroundColor Green \u0026#34;Patched - Office Version: $_\u0026#34; } else { Write-Host -ForegroundColor Red \u0026#34;Vulnerable - Office Version: $_\u0026#34; Start-Process -FilePath \u0026#34;C:\\Program Files\\Common Files\\microsoft shared\\ClickToRun\\OfficeC2RClient.exe\u0026#34; -ArgumentList {/update user} } } ","permalink":"https://www.aidenwebb.com/posts/cve-2023-23397-quickly-check-vulnerability-status-and-trigger-updates/","summary":"Yesterday Microsoft announced a new critical vulnerability CVE-2023-23397, a vulnerability in Microsoft Outlook that allows a threat actor to harvest NTLMv2 hashes via a specifically crafted Outlook appointment.\nMicrosoft state that attackers can exploit this vulnerability by sending an email that triggers automatically when it is retrieved and processed by the Outlook client. This can lead to exploitation BEFORE the email is viewed in the Preview Pane.\nThey also state that this vulnerability is being actively exploited in the wild.","title":"Cve-2023-23397 - Quickly Check Vulnerability Status and Trigger Updates"},{"content":"Do you relate to the cover photo? Have your NTFS permissions just bombed out and you can\u0026rsquo;t bare the idea of waiting hours or days for your new permissions to apply?\nDon\u0026rsquo;t worry, I\u0026rsquo;m here to help.\nIt\u0026rsquo;s no secret that applying NTFS permissions to any directory tree larger than a few thousand files quickly decends in to a painstaking waiting game. The built in UI is garbage, and icacls is decent but single-threaded and slow.\nI recently had an issue where a directory containing over 15 million files junked its permissions. Using the GUI would have taken days to reset, as would using ICACLS alone. I was not looking forward to the wait so I wrote a PowerShell script utilsing jobs to apply the permissions in parallel. I also included some logic for reporting on the current state of progress, to avoid the blind-waiting and guessing as to when it might actually finish.\nYou can adjust the script to your needs, as it stands, fire it at a directory and it will run icalcs /t /c /q /reset on the directory itself and all sub-items (folders and files) within, while keeping you updated every 30 seconds with how it\u0026rsquo;s doing.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 # Report the current state of the script function Report-ScriptStatus { param( $ScriptState ) $currentTime = Get-Date $runtime = New-TimeSpan -Start $($ScriptState.startTime) -End $currentTime Write-Host \u0026#34;-----\u0026#34; Write-Host \u0026#34;Start Time: $($ScriptState.startTime)\u0026#34; Write-Host \u0026#34;Current Time: $currentTime\u0026#34; Write-Host \u0026#34;Runtime: $runTime\u0026#34; Write-Host \u0026#34;Completed jobs: $($ScriptState.jobsCompleted.count)\u0026#34; foreach ($jobItem in $ScriptState.jobsCompleted) { Write-Host \u0026#34; - $($jobItem.Name) | $($jobItem.State) | Started: $($jobItem.PSBeginTime) | Ended: $($jobItem.PsEndTime) | Successes $($jobItem.Successes) | Failures $($jobItem.Failures)\u0026#34; } $currentlyRunningJobs = get-job | Where-Object {$_.State -eq \u0026#34;Running\u0026#34;} Write-Host \u0026#34;Currently running jobs: $($currentlyRunningJobs.Count)\u0026#34; $currentlyRunningJobs | foreach-object { Write-Host \u0026#34; - $($_.Name) | $($_.State) | Started: $($_.PSBeginTime)\u0026#34; } Write-Host \u0026#34;Next Job to Start: $($ScriptState.itemsToProcess[$ScriptState.iterator])\u0026#34; Write-Host \u0026#34;Changes Processed - Success: $($ScriptState.changesProcessedSuccess)\u0026#34; Write-Host \u0026#34;Changes Processed - Failed: $($ScriptState.changesProcessedFailed)\u0026#34; } # Parse icacls output to get the number of processed files function Get-IcaclsProcessedFiles { param ( [string]$IcaclsOutput ) \u0026lt;# .SYNOPSIS Takes the output of ICACLS and returns the number of successfully processed files. .PARAMETER IcaclsOutput The string of icacls output. EG Successfully processed 11 files; Failed processing 5 files .OUTPUTS Two numbers, the first is the number of successfully processed files, the second is the failed processed files. #\u0026gt; $successfulFiles = ($icaclsOutput.split(\u0026#34;;\u0026#34;) -replace \u0026#34;[^0-9]\u0026#34;, \u0026#39;\u0026#39;)[0] $failedFiles = ($icaclsOutput.split(\u0026#34;;\u0026#34;) -replace \u0026#34;[^0-9]\u0026#34;, \u0026#39;\u0026#39;)[1] return @($successfulFiles, $failedFiles) } # Start the job, modify the command to suit your needs function Start-IcaclsJob { param($TargetItemFullName) Write-Host \u0026#34;Starting job for item: icacls - $TargetItemFullName\u0026#34; $job = { param($loc) Invoke-Expression -Command \u0026#34;icacls $loc /t /c /q /reset\u0026#39;\u0026#34; ### ADD YOUR OWN ICACLS command/flags here } Start-Job -Name \u0026#34;icacls - $targetItemFullName\u0026#34; -ScriptBlock $job -ArgumentList $targetItemFullName } function Fix-MyDamnPermissions { param( [string]$TargetFolder, [bool]$ProcessSubfoldersOnly = $false, # Set to True to only process subfolders, not the root folder [int]$MaxConcurrentJobs = 20, [int]$TimeBetweenReportsSeconds = 30 ) $scriptState = [PSCustomObject]@{ startTime = Get-Date lastReportTime = Get-Date -Date \u0026#34;01/01/1970\u0026#34; itemsToProcess = @() iterator = 0 jobsCompleted = @() changesProcessedSuccess = 0 changesProcessedFailed = 0 exitLoop = 0 } if (-not $ProcessSubfoldersOnly) { $scriptState.itemsToProcess += Get-Item $TargetFolder } $scriptState.itemsToProcess += Get-ChildItem $TargetFolder -Depth 0 while ($true) { # Check if we have more items to process if ($scriptState.iterator -lt $scriptState.itemsToProcess.Count) { # Check if we can start new jobs $JobsRunning = get-job | Where-Object {$_.State -eq \u0026#34;Running\u0026#34;} if ($JobsRunning.Count -lt $MaxConcurrentJobs) { $nextItemToProcess = $scriptState.itemsToProcess[$scriptState.iterator] Start-IcaclsJob -TargetItemFullName $nextItemToProcess.fullname ($scriptState.iterator)++ } } else { $allJobsQueued = $true } # Tidy up completed jobs $jobsCompletedSinceLastCheck = get-job | Where-Object {$_.State -eq \u0026#34;Completed\u0026#34;} foreach ($jobItem in $jobsCompletedSinceLastCheck) { $filesprocessed = Get-IcaclsProcessedFiles -icaclsOutput $jobItem.ChildJobs[0].Output $scriptState.changesProcessedSuccess += $filesprocessed[0] $scriptState.changesProcessedFailed += $filesprocessed[1] $jobitem | add-member -type NoteProperty -Name Successes -Value $filesprocessed[0] $jobItem | add-member -type NoteProperty -Name Failures -Value $filesprocessed[1] $scriptState.jobsCompleted += $jobItem Remove-Job $jobItem } # Check if we need to process the report $timeSinceLastReport = New-TimeSpan -start $scriptState.lastReportTime -end (Get-Date) if ($timeSinceLastReport.TotalSeconds -gt $TimeBetweenReportsSeconds) { Report-ScriptStatus -ScriptState $scriptState $scriptState.lastReporttime = Get-Date } if ($allJobsQueued) { $AllJobs = get-job if ($AllJobs.Count -eq 0) { # All jobs run, report and break Report-ScriptStatus -ScriptState $scriptState # Make sure we capture anything in the final iteration ($scriptState.exitLoop)++ if ($scriptState.exitLoop -gt 1) { break } } } } } ### Example usage Fix-MyDamnPermissions -TargetFolder \u0026#34;C:\\Temp\\Permissions\u0026#34; ","permalink":"https://www.aidenwebb.com/posts/how-to-recusively-apply-ntfs-permissions-faster-using-powershell-multithreading-jobs/","summary":"Do you relate to the cover photo? Have your NTFS permissions just bombed out and you can\u0026rsquo;t bare the idea of waiting hours or days for your new permissions to apply?\nDon\u0026rsquo;t worry, I\u0026rsquo;m here to help.\nIt\u0026rsquo;s no secret that applying NTFS permissions to any directory tree larger than a few thousand files quickly decends in to a painstaking waiting game. The built in UI is garbage, and icacls is decent but single-threaded and slow.","title":"How to recusively apply NTFS permissions faster using PowerShell multithreading jobs"},{"content":"I have a hell of a lot of mail accounts, K-9 Mail on Android helps me manage them all. Here\u0026rsquo;s how to set up K-9 Mail with Office 365.\nYou will first need to set up SMTP Auth on your Exchange Tenant. This is a simple process, but it does require you to have access to the Exchange Admin Centre. If you don\u0026rsquo;t have access to the EAC, you\u0026rsquo;ll need to ask your Exchange Admin to do this for you.\nA guide is available here: https://learn.microsoft.com/en-us/exchange/clients-and-mobile-in-exchange-online/authenticated-client-smtp-submission\nIMAP (incoming) IMAP server: outlook.office365.com Security: SSL/TLS Port: 993 Username: your email Authentication: OAuth2 Auto-detect IMAP namespace: checked Use compression: checked SMTP (outgoing) SMTP server: smtp.office365.com Security: STARTTLS Port: 587 Require sign-in: checked Username: your email Authentication: OAuth2 Notes If you have 2FA enabled on your account, you will need to generate an app password for K-9 Mail to use. This is a one-time password that you can generate in the Office 365 portal. Auto-detect IMAP namespace is a new feature in K-9 Mail 5.800. It allows K-9 Mail to automatically detect the namespace of your IMAP server. This is useful if you have multiple mailboxes on the same server, as it allows you to select which mailbox you want to use. auto-detect IMAP namespace is not available in K-9 Mail 5.600 and older. If you are using K-9 Mail 5.600, you will need to manually set the namespace to \u0026ldquo;INBOX.\u0026rdquo;. ","permalink":"https://www.aidenwebb.com/posts/how-to-set-up-k-9-mail-with-office-365/","summary":"I have a hell of a lot of mail accounts, K-9 Mail on Android helps me manage them all. Here\u0026rsquo;s how to set up K-9 Mail with Office 365.\nYou will first need to set up SMTP Auth on your Exchange Tenant. This is a simple process, but it does require you to have access to the Exchange Admin Centre. If you don\u0026rsquo;t have access to the EAC, you\u0026rsquo;ll need to ask your Exchange Admin to do this for you.","title":"How to set up K-9 Mail With Office 365"},{"content":"You know the drill, as the kid with the tech skills you get roped into helping your parents and other family members with their busted tech. I notice that every time I ressurect or reincarnate the treasured device of a family member I end up installing much of the same software. I wrote this to save me some time, and to help others who are in the same boat.\nMy preferred recommendation in each category is in bold. Most suggestions are free, but some are paid. I have tried to indicate paid software with a $.\nWhen a friend or family member asks me for advice on software to install, I\u0026rsquo;ll point them to this page.\nI\u0026rsquo;ll update this every now and then, please let me know if you have any suggestions.\nWindows 10 / 11 Remote Support Connectwise Control TeamViewer Browsers Firefox Recommended Plugins uBlock Origin - Ad Blocker BitWarden - Password Manager Password Manager BitWarden Anti-Virus Windows Defender Anything else is a waste of money and resources and many options are honestly worse than a virus. Video Player VLC Music Player Foobar2000 Spotify Image Viewer IrfanView Free for non commercial use, has a paid version with more features Windows 10 has a built in image viewer that\u0026rsquo;s pretty good for most. Image Editor Paint.net * Easy to use GIMP * More advanced akin to Photoshop Krita * More advanced -for digital art. Disk Usage Evaluator WinDirStat File Compression 7-Zip Text Editor Notepad++ Office Suite LibreOffice Microsoft Office - $ Google Docs Mail Client Thunderbird Outlook - $ PDF Reader Foxit Reader Adobe Acrobat Reader Messengers Discord Skype Telegram WhatsApp Signal - Free and very secure instant messenger Video Conferencing Zoom Microsoft Teams Google Meet Android Free Open Source Software Manager F-Droid * If you know what you\u0026rsquo;re doing Many of the below recommendations can be found on F-Droid free of charge even if they\u0026rsquo;re paid in the Play Store. Browsers Firefox Password Manager Bitwarden Anti-Virus Don\u0026rsquo;t even bother with 3rd party AV\u0026rsquo;s on Mobile. It\u0026rsquo;s a waste of resources and battery life Video Player VLC Music Player Poweramp Image Viewer Simple Gallery Image Editor Photo Editor Disk Usage Evaluator DiskUsage File Compression Zipper Text Editor Simple Text Editor Office Suite LibreOffice Microsoft Office - $ Google Docs Mail Client K-9 Mail Outlook - $ PDF Reader Foxit Reader Messengers Discord Skype Telegram WhatsApp Signal - Free and very secure instant messenger Video Conferencing Zoom Microsoft Teams Calendar App Simple Calendar Calendar Sync (CalDav / CardDav) Slightly more advanced, but still relatively simple to set up.\n-DAVx5\nNoteTaking App Obsdian MD - Powerful linking but with a learning curve. JTX Board - Simple and easy to use. Combines journaling, note taking and tasks in to one app. Podcast App AntennaPod Weather App Met Office Simple Weather Yr ","permalink":"https://www.aidenwebb.com/posts/standard-list-of-software-i-install-on-my-mums-computer-and-phone/","summary":"You know the drill, as the kid with the tech skills you get roped into helping your parents and other family members with their busted tech. I notice that every time I ressurect or reincarnate the treasured device of a family member I end up installing much of the same software. I wrote this to save me some time, and to help others who are in the same boat.\nMy preferred recommendation in each category is in bold.","title":"Standard list of software I install on my mums computer and phone"},{"content":"3CX have updated their docs and removed help.3cx.com meaning the old documentation for updating SSL certs is now gone, or at least harder to find.\nThe original URL was https://help.3cx.com/help/en-us/33-installation/148-how-can-i-replace-the-ssl-certificates-for-a-custom-domain. If anyone has a copy of this page, please let me know.\nThankfully updating the SSL certificate is relatively straight forward as the web client runs on nginx.\nUpdating the SSL Certificate Prerequisites You will need:\nAccess to the server running 3CX Remote Desktop (Windows) SSH (Linux) The certificate and private key in PEM format Updating the Certificate Locate the certificate folder (default):\nWindows: C:\\Program Files\\3CX Phone System\\Bin\\nginx\\conf\\instance1 Linux: /var/lib/3cxpbx/Bin/nginx/conf/Instance1 Copy the certificate and private key into the folder and rename them to \u0026lt;yourdomain\u0026gt;-crt.pem and \u0026lt;yourdomain\u0026gt;-key.pem respectively. EG:\nmydomain-com-crt.pem mydomain-com-key.pem Restart Nginx Restart the nginx service to apply the new certificate.\nWindows: net stop nginx then net start nginx Linux: systemctl restart nginx ","permalink":"https://www.aidenwebb.com/posts/how-to-replace-ssl-certificates-for-a-custom-domain-in-self-hosted-3cx/","summary":"3CX have updated their docs and removed help.3cx.com meaning the old documentation for updating SSL certs is now gone, or at least harder to find.\nThe original URL was https://help.3cx.com/help/en-us/33-installation/148-how-can-i-replace-the-ssl-certificates-for-a-custom-domain. If anyone has a copy of this page, please let me know.\nThankfully updating the SSL certificate is relatively straight forward as the web client runs on nginx.\nUpdating the SSL Certificate Prerequisites You will need:\nAccess to the server running 3CX Remote Desktop (Windows) SSH (Linux) The certificate and private key in PEM format Updating the Certificate Locate the certificate folder (default):","title":"How to replace SSL certificates for a custom domain in Self Hosted 3CX"},{"content":"I occurs to me that each time I set up a new system, or re-install my workstation, I often end up hunting down and redownloading tools and software that I use on a regular basis. So I thought I\u0026rsquo;d create a list of useful tools and pop it here on my blog for future reference and to share with others.\nI\u0026rsquo;ll try to keep this list updated as I find new tools and software that I find useful.\nIf you have any suggestions, please open an Issue or Pull Request on the Github Repo\nBold items are highly recommended and I use them on a daily basis.\nGeneral Name Description Link 7-Zip A file archiver https://www.7-zip.org/ Notepad++ A free source code editor and Notepad replacement that supports several languages. https://notepad-plus-plus.org/ Vscode A free source code editor developed by Microsoft for Windows, Linux and macOS. Extension library means it can be used for pretty much anything involving typing https://code.visualstudio.com/ Obsidian MD A note-taking and knowledge base tool that works on Windows, macOS, and Linux. https://obsidian.md/ Greenshot A screenshot tool that allows you to capture a screen, or part of it, to a file or to the clipboard. https://getgreenshot.org/ Git A distributed version control system designed to handle everything from small to very large projects with speed and efficiency. https://git-scm.com/ WinDirStat A disk usage statistics viewer and cleanup tool for various versions of Microsoft Windows. https://windirstat.net/ WizTree A faster disk usage statistics viewer and cleanup tool for various versions of Microsoft Windows. https://wiztreefree.com/ VLC A cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols. https://www.videolan.org/vlc/index.html Audacity A cross-platform audio software for multi-track recording and editing. https://www.audacityteam.org/ OBS Studio A free and open source cross-platform software for video recording and live streaming. https://obsproject.com/ Yubikey Manager Cross-platform application for configuring any YubiKey. https://developers.yubico.com/yubikey-manager/ / https://www.yubico.com/support/download/yubikey-manager/ Voidtools Everything A file search tool that locates files and folders by filename instantly for Windows. https://www.voidtools.com/ Development Name Description Link Docker Desktop A cross-platform application for the building and sharing of containerized applications and microservices. https://www.docker.com/products/docker-desktop Docker Compose A tool for defining and running multi-container Docker applications. https://docs.docker.com/compose/ VsCode A free source code editor developed by Microsoft for Windows, Linux and macOS. Extension library means it can be used for pretty much anything involving typing https://code.visualstudio.com/ Git A distributed version control system designed to handle everything from small to very large projects with speed and efficiency. https://git-scm.com/ Jetbrains Toolbox A cross-platform application for managing JetBrains tools. https://www.jetbrains.com/toolbox-app/ System Administration Name Description Link Devolutions Remote Desktop Manager A cross-platform application for managing remote connections and virtual machines. https://devolutions.net/products/remote-desktop-manager Forensit Transwiz Migrate from one computer to another easily https://www.forensit.com/move-computer.html Forensit Domain Migration Migrate computers to a new domain (including Azure AD) easily https://www.forensit.com/domain-migration.html Azure CLI A cross-platform command-line tool for managing Azure resources. https://docs.microsoft.com/en-us/cli/azure/install-azure-cli-windows?view=azure-cli-latest Azure PowerShell A cross-platform command-line tool for managing Azure resources. https://docs.microsoft.com/en-us/powershell/azure/install-az-ps?view=azps-6.4.0 PowerShell A cross platform task automation solution https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell?view=powershell-7.2 WinSCP A SFTP, SCP, FTPS, and FTP client for Windows. https://winscp.net/eng/index.php Nirsoft Toolkit A collection of small and useful freeware utilities. https://launcher.nirsoft.net/downloads/index.html SysInternals Suite A set of powerful utilities for Windows https://docs.microsoft.com/en-us/sysinternals/downloads/sysinternals-suite Application and Installer Management Name Description Link USSF - Ultimate Silent Switch Finder Finds silent install switches for exe and msi installers https://deployhappiness.com/the-ultimate-exe-silent-switch-finder/ Ninite Install and update all your programs at once https://ninite.com/ Chocolatey The package manager for Windows https://chocolatey.org/ Scoop A command-line installer for Windows https://scoop.sh/ WinGet The Windows Package Manager https://learn.microsoft.com/en-us/windows/package-manager/winget/ AppGet The Windows Package Manager https://appget.net/ Rufus Create bootable USB drives the easy way https://rufus.ie/ Ventoy Bootable USB drives made even easier https://www.ventoy.net/en/index.html CMTrace A tool for viewing and analyzing Configuration Manager logs https://www.microsoft.com/en-us/download/details.aspx?id=50032 Networking Name Description Link Wireshark Network protocol analyzer https://www.wireshark.org/ NetCrunch Tools A collection of free network tools for network monitoring, troubleshooting, and security. https://www.adremsoft.com/netcrunch-tools/ Security Name Description Link HashCheck A utility that computes and verifies hash values for files https://sourceforge.net/projects/hashcheck/ BitWarden A password manager https://bitwarden.com/ Virtualisation Name Description Link Hyper-V A native hypervisor for Windows 10 https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v VirtualBox A virtualisation tool https://www.virtualbox.org/ VMware Workstation A free virtualisation tool https://www.vmware.com/uk/products/workstation-pro.html ","permalink":"https://www.aidenwebb.com/posts/useful-tools-for-sysadmins-and-techies/","summary":"I occurs to me that each time I set up a new system, or re-install my workstation, I often end up hunting down and redownloading tools and software that I use on a regular basis. So I thought I\u0026rsquo;d create a list of useful tools and pop it here on my blog for future reference and to share with others.\nI\u0026rsquo;ll try to keep this list updated as I find new tools and software that I find useful.","title":"Useful Tools for SysAdmins and Techies"},{"content":"There are currently over 50,000 free books to choose from on Amazon\u0026rsquo;s Kindle Store. Just add a book to your library using the Buy now button (not Subscribe to Kindle Unlimited / Read for £0.00) and read with Amazon Cloud reader in a web browser or sync to your Kindle.\nThe below link will open a filtered search on the Amazon UK website showing ALL the books that are currently FREE to add to your account without needing a Kindle unlimited subscription.\nClick here to go to Amazon or scroll down and scan the QR code at the bottom of the page.\nThis saves a lot of time scrolling through the Freebies section clicking one free book deal at a time only to find they are no longer free.\nI\u0026rsquo;d suggest saving the link and then filter on your Genre/Requirements.\nHappy freebie hunting!\n","permalink":"https://www.aidenwebb.com/posts/how-to-get-free-ebooks-all-the-kindle-store-free-ebooks-on-one-link/","summary":"There are currently over 50,000 free books to choose from on Amazon\u0026rsquo;s Kindle Store. Just add a book to your library using the Buy now button (not Subscribe to Kindle Unlimited / Read for £0.00) and read with Amazon Cloud reader in a web browser or sync to your Kindle.\nThe below link will open a filtered search on the Amazon UK website showing ALL the books that are currently FREE to add to your account without needing a Kindle unlimited subscription.","title":"How to get FREE eBooks - All the Kindle Store free eBooks on one link"},{"content":"1. The Default Bridge This is the default network that new containers will connect to. It\u0026rsquo;s a software bridge between your docker instance and your host system, providing isolation between the bridge network and other networks, including the host network and other bridge networks on the host. Docker best practices discourage using this network for containers, recommending User-Defined bridges instead, which we will get to in #4.\nWhen to use it: Avoid using the Default Bridge, use another network type instead where possible\n2. The Default Host The host network mode is just that, containers are connected directly to the same network as the host. Containers are not isolated from the network or the host in this mode. The host and the container share all their open ports and network configurations. The container runs as though it was an application on the host.\nThe host network mode Linux only and is not supported on Windows or Mac.\nWhen to use it: Handy when a container needs to expose a large number of ports, or the container runs an application that you would like to act as if running natively. Useful for things like VPN servers for example\n3. The Default None Does what it says on the tin, the container is not connected to any network.\nWhen to use it: When you don\u0026rsquo;t want a container to be connected to a network at all. Useful for complete network isolation for containers that don\u0026rsquo;t need network access. Containers exclusively operating on files on a volume such as producing backups, artifacts, or auditing for example.\n4. The User Defined Bridge User defined bridges are just like the default bridge, except they come with a number of perks.\nAutomated DNS resolution Containers within a user-defined bridge are able to automatically resolve eachother by their container name or alias. Containers on the default bridge network can only resolve eachother by their IP addresses unless you use the legacy --link option. In a situation where you have a web and db container in a user-defined bridge network, the web container can connect to the db container simply by connecting to the db host name, no matter which Docker host the application stack is running on. This is especially useful as containers IP addresses may often change when redeployed.\nBetter isolation All containers without the --network flag defined are by default attached the the default bridge network, which can be risky as unrelated stacks, services and containers are able to communicate.\nOn-the-fly attachment and detachment Containers can be connected or disconnected from user-defined networks while running. In order to connect or remove a container from the default bridge, the container must be stopped and recreated.\nCongigurable network settings User-defined bridges can be configured with different/non-standard network settings, like changing the MTU or iptables rules.\nYou can create a new user-defined bridge network by running docker network create \u0026lt;network-name\u0026gt;.\nWhen to use it: Most of the time, you will want to create your containers in their own user-defined networks. Running a stack of applications in a user-defined network for that stack enables each container in the stack to talk to each other, but without exposing the containers to anything more than necessary. A stack containing a web and db container might expose port 80 to the web, but keep the database completely isolated.\n5. The Overlay Network A distributed network that can be shared among multiple Docker hosts. It sits on top of the host=specific networks and allows contaienrs connected to it to communicate with eachother. Docker handles the routing of packets to and from their respective hosts and containers. This is not supported by Windows nodes.\nWhen to use it: When you have a large number of docker hosts in a swarm, and want them to be able to communicate with eachother at a greater level of abstraction.\n6. The MACVLAN Bridge Mode MACVLAN networks are bound directly to the physical port on the host, and configured to communicate directly to the physical networks. Containers have their own MAC addresses and IP addresses, similar to as though they were virtual machines. Some networks will not allow multiple MAC addresses to be available on one Switch port, and so Promiscuous mode must be enabled on each device between the host and the router.\nContainers in a MACVLAN must be manually assigned their own IP addresses as they won\u0026rsquo;t get DHCP addresses from the router. This is because Docker will apply its own DHCP addresses to the container.\nThis can be created by running: docker network create -d macvlan --subnet 10.1.2.0/24 --gateway 10.1.2.1 -o parent=\u0026lt;physical-host-NIC\u0026gt; \u0026lt;network-name\u0026gt;\nWhen to use it: When you want your containers to act as though they\u0026rsquo;re physical devices on the same network as your router, and avoid the abstraction layers of Docker and the host. Could be useful for applications that require Layer 2 networking or their own MAC addresses to operate.\n801.1q Mode Works just like the Bridge Mode, but can also be configured with VLANs as sub-interfaces.\nThis can be created by running: docker network create -d macvlan --subnet 10.1.2.0/24 --gateway 10.1.2.1 -o parent=\u0026lt;physical-host-NIC\u0026gt;.50 \u0026lt;network-name\u0026gt;\nWhen to use it: When you want your containers to also be VLAN aware\n7. The IPVLAN Works similarly to MACVLAN but with the difference of all containers within using the same MAC address as the host interface. This means we don\u0026rsquo;t need to fight with Promiscuous mode. Works similarly to the HOST mode, but can specify a second host interface. IPVLAN also support VLAN sub-interfaces.\nThis can be created by running: docker network create -d ipvlan --subnet 10.1.2.0/24 --gateway 10.1.2.1 -o parent=\u0026lt;physical-host-NIC\u0026gt; \u0026lt;network-name\u0026gt;\nWhen to use it: When you want your containers to act as though they\u0026rsquo;re on the same network as your router, but do not require their own MAC addresses.\nIPVLAN L3 Mode Adds Layer 3 routing to the network mode. This means no switches, no ARP, and no broadcast/multicast traffic coming out of the host. The host then acts as a router.\nThis can be created by running: docker network create -d ipvlan --subnet 10.1.2.0/24 --gateway 10.1.2.1 -o ipvlan_mode=l3 \u0026lt;network-name\u0026gt;\nWhen to use it: When you the host to act as a router for containers in the network, stopping broadcast traffic from containers from reaching the network the host is attached to.\n","permalink":"https://www.aidenwebb.com/posts/dockers-seven-network-types-and-when-to-use-them/","summary":"1. The Default Bridge This is the default network that new containers will connect to. It\u0026rsquo;s a software bridge between your docker instance and your host system, providing isolation between the bridge network and other networks, including the host network and other bridge networks on the host. Docker best practices discourage using this network for containers, recommending User-Defined bridges instead, which we will get to in #4.\nWhen to use it: Avoid using the Default Bridge, use another network type instead where possible","title":"Dockers seven network types and when to use them"},{"content":"Headnotes First, the project link, for those of you who just want to gander at code and commit history\nSecond, this post uses some Mermaid JS graphs, which don\u0026rsquo;t look great on a dark background, so I recommend switching the site to light mode by clicking the little sun next to \u0026ldquo;Home\u0026rdquo; in the navbar.\nIntroduction Last night was one of the worst night\u0026rsquo;s sleep I\u0026rsquo;ve had in the past few years. I\u0026rsquo;ve always had trouble with insomnia, but have built a number of techniques to work through it and eventually sleep. One of those techniques is to just get up and write down whatever comes to mind until my ADHD brain is quiet enough to sleep without sprinting through the supermarket shelves of ideation, scooping armfuls of ideas in to the shopping trolley of \u0026ldquo;Projects I should start\u0026rdquo;.\nAnd write I did! Among one of the many things that came up was \u0026ldquo;I want to learn C# / .NET Core, and I feel like I\u0026rsquo;m making reasonably good progress. I have lots of ideas for apps I want to make, but they\u0026rsquo;re primarily solving business problems and at my current skill level none of them are going to be good enough for production. What would be a good project sufficiently complicated to maintain my interest, where I can start very simple and iteratively make improvements, where any bugs in the code aren\u0026rsquo;t going to be extremely detrimental to the use of the project.\nAfter another hour staring out the window at empty street outside our flat, watching the occasional bat flit through the sky eating mosquito\u0026rsquo;s, the idea came to me. Why not make a text-based MUD?\nWhat is a MUD? MUD stands for Multi-User-Dungeon. It\u0026rsquo;s very much the grandfather of modern MMORPG\u0026rsquo;s such as Runescape and World of Warcraft. Not nearly as polished, and typically without a GUI, they\u0026rsquo;re primarily text-based, making it perfect for a simple console application without having to worry about graphics, sounds or real-time / reaction speed-based event handling.\nWhy a MUD? Well, from a design perspective, we can start with a very simple project and build a lot more complexity as we go. At the most basic level, we only need 4 components:\nThe Player / Character Rooms in a dungeon Monsters in a room Treasure dropped by monsters, or found in a room At a more complicated level, we can add:\nCharacter skills and variables, such as fighting, crafting, luck Status effects for skills, room environments, special abilities, monsters Various items equipable by the character, or monsters/npcs Different dungeons, either randomly generated or static Ways to gain or spend money found in rooms Adding a GUI / maps to rooms, allowing for 2 dimensional, or 3 dimensional rooms rather than a 1 dimensional room simply existing as a container of the things within. Adding 2d or 3d movement within a GUI map, rather than a player and monsters simply existing in a room, they could move around and between rooms. At a technical level The control plane is simple - written text-based commands sent to a console. I will need to learn about and build an interface for these text-based commands and the response, so a telnet server will likely fill this function to begin with. At a later, more complicated level, developing an own client and a GUI and encoding the control protocol might be on the cards.\nAt a motivational level It\u0026rsquo;s fun! I love RPG\u0026rsquo;s and DnD. This has the potential to just be a big mess of unbalanced ideas, but that\u0026rsquo;s OK, it\u0026rsquo;s a project for fun. If for whatever reason it does take off, I certainly won\u0026rsquo;t be complaining. As someone who used to run private game servers in my teens, I enjoy building a community of players, adapting the game to suit what players want, and knowing people are enjoying what I\u0026rsquo;ve built.\nAt a risk level If the server breaks, or data is lost, or there\u0026rsquo;s a bug that leaks information, or the systems get hacked. That really sucks, but at least no-one is relying on it. Also, no GDPR protected personal information stored means a lot less stress.\nAt an educational level There\u0026rsquo;s lots of concepts to learn at a basic level, and then deep dive in to if and when required. For example:\nClient / Server communication. Start with Telnet, maybe at a later point REST with a web-page front end, or a custom/another protocol and a dedicated game client. Authentication / Authorisation - Users are going to need to log in to play their characters at some level. Likely rolling my own to begin with (a bad idea in production, but a good learning experience). All players have the same in-game permissions, but their characters may not be able to access some items/areas without the correct stats/quests completed, which is adjacent to Authorisation. Persistent data storage - in a database or in flat files. I\u0026rsquo;m thinking a graph database is a good fit for this kind of project. A big relational databased is likely to get complicated quickly. Game/interface design - Even business applications can benefit from elements of game design. When you\u0026rsquo;re trying to drive the behaviour of a user to interact with your business application in the most productive way, understanding what draws people to take specific actions when faced with a particular scenario comes in handy. So where do we start? Designing the MVP, or more like a prototype The absolute most basic base-product. Doesn\u0026rsquo;t need reward cycles built at this point, only the basic fundamentals at this stage\nSingle player Played in the local systems console Concept:\nThe dungeon: A dungeon contains a randomly generated list of rooms. Each room contains a monster, and an exit. The monster in the room must be killed before moving to an exit. The player: The player keeps track of how many monsters have been killed The player starts in the first room of a randomly generated dungeon When the player dies, their high-score is how many monsters they have killed, and they start a new randomly generated dungeon. \u0026ldquo;That sounds boring, you don\u0026rsquo;t even have a choice as a player, it\u0026rsquo;s just kill monster, next room, kill monster, next room\u0026rdquo;\nYou\u0026rsquo;re right, we do need to make this more fun, but at this stage, we just want something that works. A prototype.\nSome idea\u0026rsquo;s I\u0026rsquo;ve had about gameplay elements to make things more fun.\nDifferent monsters. Some might be flying and out of reach of a sword, but can be shot at, some might be armoured but susceptible to magic. Some might have elemental resistances or weaknesses. Some monsters might be able to be charmed, or spoken with, or dealt with in ways other than combat. Different attack styles for both players and monsters. Players might choose to prefer melee, ranged, or magical combat. Some players might want pacifist options. Different doors leading to different rooms. Different doors indicating the type of room or monster that might be behind it. Doors covered in vines, ice or hot to touch for example, allowing a player to choose their preferred next challenge. Monsters granting XP for killing them, which can be allocated to doing more damage, or increasing your health Monsters dropping items that can be equipped for particular affects, advantages or stat changes, or otherwise used throughout the dungeon It\u0026rsquo;s still \u0026ldquo;kill monster, next room\u0026rdquo;, but now has a lot of elements of choice that allow players to develop strategy in tackling the dungeon.\n\u0026ldquo;But this isn\u0026rsquo;t even a MUD, it sounds like a roguelike single player dungeon crawl\u0026rdquo;\nYup, but it also makes the basis of a MUD to be. We add a level of abstraction and instead of \u0026ldquo;Dungeon\u0026rdquo; we have a \u0026ldquo;Map\u0026rdquo;, within the Map, we have a list of \u0026ldquo;Areas\u0026rdquo; instead of \u0026ldquo;Rooms\u0026rdquo;. \u0026ldquo;Areas\u0026rdquo; contain NPC\u0026rsquo;s, monsters, items, trees etc, and can be navigated by players.\nWe can still use randomly generated dungeons per player if we want to, and access that through an area of the overall map.\nAn admission of over-enthusiastic guilt I actually designed the MVP after I\u0026rsquo;d already got started hacking together some basic code. A result of this is that I\u0026rsquo;ve added unnecessary complexity to the project before I\u0026rsquo;ve even started. To solve this I\u0026rsquo;ll need to remove that complexity a this stage and re-implement it later. For example, I\u0026rsquo;ve already started writing a TCPServer listener, and each room actually generates random exits, and the player class has controls to allow directional movement, which won\u0026rsquo;t be useful until different exits have meaning.\nThe lesson learned? Hash out the MVP on paper before hacking around with code. It can also be a good idea to hash out your basic class diagrams too, so lets do that now.\nHashing out the building blocks - Classes Our basic 4 classes are:\nclassDiagram class Dungeon{ +List~Room~ Rooms +GenerateRooms() +DescribeDungeon() } class Room{ +int RoomID +List~Objects~ Contents +GenerateContents() +DescribeRoom() } class PlayerCharacter{ +int Health +int Level +int Position +Attack() +Defend() +Move() } class Monster{ +int Health +int Level +int Position +Attack() +Defend() } Monster and Player Character look very very similar, so lets abstract out to another class.\nclassDiagram ICharacter \u003c|.. PlayerCharacter ICharacter \u003c|.. Monster IFightable \u003c|.. PlayerCharacter IFightable \u003c|.. Monster class Dungeon{ +List~Room~ Rooms +GenerateRooms() +DescribeDungeon() } class Room{ +int RoomID +List~Objects~ Contents +GenerateContents() +DescribeRoom() } class ICharacter{ +string Name +int Position +Move() } class IFightable{ +int Health +int Level +Attack() +Defend() } class PlayerCharacter{ placeholder } class Monster{ placeholder } So, lets go back to pure basics and impliment this.\nFirst off, I\u0026rsquo;m going to move my master branch to a new branch called \u0026ldquo;firstproto\u0026rdquo;, so I can develop this design separately to the small amount of work I\u0026rsquo;ve already done. That work may be useful at a later stage, it may not be. If it\u0026rsquo;s not, I\u0026rsquo;ll delete that prototype branch.\nSecond, I\u0026rsquo;m going to remake a \u0026ldquo;main\u0026rdquo; branch and a \u0026ldquo;dev\u0026rdquo; branch, I\u0026rsquo;ll develop on the dev branch and pull in to main at key milestones. Sensible!\n1 2 git checkout -b first-prototype // create prototype branch git push origin first-prototype // push the origin to prototype branch Log in to Github, go to the repo settings \u0026gt; branches \u0026gt; set \u0026lsquo;first-prototype\u0026rsquo; as the default branch 1 2 3 git push origin :master // delete the master branch git checkout --orphan main git checkout --orphan dev Created a Readme.MD on dev branch with a title only and saved. 1 2 3 4 5 6 7 8 9 10 11 12 13 git checkout dev git rm --cached * git status git add README.MD git commit -m \u0026#34;First commit - add readme\u0026#34; git add .gitignore git add .gitattributes git commit -m \u0026#34;add gitattributes and .gitignore\u0026#34; git push origin dev git checkout main git merge dev git push origin main git checkout dev Log in to Github, go to the repo settings \u0026gt; branches \u0026gt; set \u0026lsquo;main\u0026rsquo; as the default branch Add files for each class/interface to be used in the program Now the git mess is cleared up, and I\u0026rsquo;ve templated the project, that\u0026rsquo;s where I\u0026rsquo;ll leave it for now. The code is empty of any domain-specific code, and does nothing, but here we have a start! - Github commit\n","permalink":"https://www.aidenwebb.com/posts/learning-c-sharp-building-a-mud-part-1/","summary":"Headnotes First, the project link, for those of you who just want to gander at code and commit history\nSecond, this post uses some Mermaid JS graphs, which don\u0026rsquo;t look great on a dark background, so I recommend switching the site to light mode by clicking the little sun next to \u0026ldquo;Home\u0026rdquo; in the navbar.\nIntroduction Last night was one of the worst night\u0026rsquo;s sleep I\u0026rsquo;ve had in the past few years.","title":"Learning C# - Building a MUD Part 1"},{"content":"Introduction I\u0026rsquo;m off to Me\u0026rsquo;ra Luna in a few days! This is my first time camping since the Covid pandemic and thankfully I uncovered a previous camping packing list. I figure I may as well share it here for easy finding in future and so others may find it useful. Bring on the festival!\nA place to rest Tent Tent Pegs Mallet Mattress Air Mattress pump Sleeping bag Pillow Folding chair Torch Look after yourself Clothes Wet weather clothes / spare shoes / boots / rain coat Toothbrush / Toothpaste / Floss Shower Gel Painkillers Sun Cream Sun Glasses Condoms Wet Wipes Cutlery / Plates / Mess Tins / Mug Food Water Bottle(s) Towel First Aid kit Toilet roll Thermals / Sleeping clothes Deodrant Tick removers Sanitary towels / tampons (even for guys, they come in handy often!) Misc ID / Passport / Covid pass Cash Duct Tape Bin Bags Folding trolley / Tarp / Bunjee cords Lighter Day bag Pocket Knife Booze (remember to decant in to non-glass bottles) Spare glasses case A book / kindle ","permalink":"https://www.aidenwebb.com/posts/camping-packlist/","summary":"Introduction I\u0026rsquo;m off to Me\u0026rsquo;ra Luna in a few days! This is my first time camping since the Covid pandemic and thankfully I uncovered a previous camping packing list. I figure I may as well share it here for easy finding in future and so others may find it useful. Bring on the festival!\nA place to rest Tent Tent Pegs Mallet Mattress Air Mattress pump Sleeping bag Pillow Folding chair Torch Look after yourself Clothes Wet weather clothes / spare shoes / boots / rain coat Toothbrush / Toothpaste / Floss Shower Gel Painkillers Sun Cream Sun Glasses Condoms Wet Wipes Cutlery / Plates / Mess Tins / Mug Food Water Bottle(s) Towel First Aid kit Toilet roll Thermals / Sleeping clothes Deodrant Tick removers Sanitary towels / tampons (even for guys, they come in handy often!","title":"Camping Packlist"},{"content":"Authentication Authentication is saying \u0026ldquo;I am me\u0026rdquo;. It validates who you are. When you go to a club and the bouncer stops you and you tell him you\u0026rsquo;re on the guest list, you then show him your ID and he says \u0026ldquo;Ahh! You\u0026rsquo;re that guy, come on in\u0026rdquo; - that\u0026rsquo;s Authentication\nAuthorisation Authorisation validates what you claim to be. Going back to the club and the bouncer stops you. You show him your ID. He authenticates you and that your ID belongs to you by checking your picture matches your face. He then checks your authorisation by checking your date of birth to validate that you\u0026rsquo;re old enough to come in, but otherwise doesn\u0026rsquo;t care who you are. He only cares about your age. Your date of birth here is what\u0026rsquo;s called a claim. It\u0026rsquo;s something your ID token claims to be true about you.\nAccounting Accounting validates what you do once you have access. Back to the club, the bouncer gives you a wristband. This wristband is used for everything at the club, from buying drinks, to accessing the dancefloor, to going to the toilet. Every time your wristband is used, where and when it is used is logged. These logs in aggregate form a detailed picture of what you did during your time at the club.\n","permalink":"https://www.aidenwebb.com/posts/whats-the-difference-between-authentication-authorisation-and-accounting-aaa/","summary":"Authentication Authentication is saying \u0026ldquo;I am me\u0026rdquo;. It validates who you are. When you go to a club and the bouncer stops you and you tell him you\u0026rsquo;re on the guest list, you then show him your ID and he says \u0026ldquo;Ahh! You\u0026rsquo;re that guy, come on in\u0026rdquo; - that\u0026rsquo;s Authentication\nAuthorisation Authorisation validates what you claim to be. Going back to the club and the bouncer stops you. You show him your ID.","title":"What's the difference between Authentication, Authorisation and Accounting? (AAA)"},{"content":"Submodules aren\u0026rsquo;t removed using git rm submodule-dir, they need to be removed in a far more thorough and annoying fashion. There are a number of unclear explanations at various sources so I decided to write my own findings.\nDelete the relevant parts from the .gitmodules file.\nEG:\n1 2 3 [submodule \u0026#34;blog/themes/PaperMod\u0026#34;] path = blog/themes/PaperMod url = https://github.com/adityatelange/hugo-PaperMod.git Stage .gitmodules via git add .gitmodules\nRemove the relevant parts from .git/config\nEG:\n1 2 [submodule \u0026#34;blog/themes/PaperMod\u0026#34;] url = https://github.com/adityatelange/hugo-PaperMod.git Clear the cache with git rm --cached /path/to/submodule - with no trailing slash. Including the trailing slash will throw an error\nRemove the .git modules submodule data by running rm -rf .git/modules/submodule_name or rm -rf .git/modules/submodulefoldername\nCommit the changes\nDelete the submodule files rm -rf path/to/submodule\n","permalink":"https://www.aidenwebb.com/posts/git-remove-submodule/","summary":"Submodules aren\u0026rsquo;t removed using git rm submodule-dir, they need to be removed in a far more thorough and annoying fashion. There are a number of unclear explanations at various sources so I decided to write my own findings.\nDelete the relevant parts from the .gitmodules file.\nEG:\n1 2 3 [submodule \u0026#34;blog/themes/PaperMod\u0026#34;] path = blog/themes/PaperMod url = https://github.com/adityatelange/hugo-PaperMod.git Stage .gitmodules via git add .gitmodules\nRemove the relevant parts from .git/config","title":"Git Remove Submodule"},{"content":"Introduction I recently came to the conclusion that I wasn\u0026rsquo;t posting on my blog nearly as much as I\u0026rsquo;d like to. My blog runs on WordPress, and I\u0026rsquo;ve felt for a while that the process of logging in, creating a post, fixing formatting in a WSYWGI editor and eventually posting was too much resistance when I commonly just write notes in plain text. So, why not just write posts in plain text and have something else do the work of turning that in to a post or a blog?\nIn comes Hugo, a static site generator written in Go.\nGetting Started Installing Hugo First off, I used Chocolatey to install Hugo:\n1 choco install hugo Adding a theme I liked the look of the PaperMod theme, simple yet effective. I initially installed using Method 1 - cloning the PaperMod theme directly in to my own code. This caused a bit of faff with git that I didn\u0026rsquo;t want to troubleshoot so I scrapped that and installed via Method 2 - pulling PaperMod in as a submodule.\n1 2 git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) I then spent a bit of time tinkering with the config and a test Lipsum post (which I then updated to this post).\nI\u0026rsquo;m not yet ready to scrap my existing WordPress install, I want to get more familiar with the workings of Hugo first, integrate comments, search etc. So I decided to host Hugo off of GitHub Pages as an intermediary step. GitHub Pages doesn\u0026rsquo;t support Hugo out of the box though. However, GitHub Pages does support just serving raw static HTML/CSS/JS so I created a separate repository (now deleted as I now serve from a gh-pages branch) and imported this as a submodule in the /public/ folder that Hugo uses to publish, we should be able to publish the generated static site directly in to the GitHub Pages repository\nPublishing the site in a roundabout way It\u0026rsquo;s worth noting you cannot clone an empty repository - you must commit something to the repo before cloning it. I committed a quick readme.md.\n1 git submodule add -b main https://github.com/Aidenwebb/aidenwebb.github.io.git public After generating the site with hugo -t PaperMod: Navigate to your public directory and run:\n1 2 3 4 cd public git add . git commit -m \u0026#34;init commit\u0026#34; git push origin main and the submodule remote repo will be updated, and built by GitHub Pages.\nCSS broke, I\u0026rsquo;ll fix that later When hosting on GitHub pages, something breaks the integrity of CSS files, so I\u0026rsquo;ve opted to disable fingerprinting (config.yml:params:assets:disablefingerprinting:true) for the time being with the intention of investigating further another time.\nGit and empty folders = a confusing folder structure Moving to another workstation, I noted after pulling my repository that much of the folder structure was missing. Hugo generates a lot of empty folders when it creates a new site, and git does not store empty folders. I regenerated the site with Hugo, and added a .gitkeep file to each empty folder, committing this to the repository.\nBack to theming, and Publishing the site through Github Actions instead of maintaining two repos I populated the config.yml with settings from Papermod\u0026rsquo;s example, tweaking them to suit my needs, then added search and tags. The process of committing to two repositories for code updates and then building and publishing the site from my local system was getting tedious quickly, and after a quick search I was pleased to find that the Hugo documentation included instructions for a gh-pages workflow. After some minor modifications and messing with removing my existing submodule and related cache, I had Hugo publishing through CI/CD to GitHub pages. I then deleted my \u0026ldquo;publishing\u0026rdquo; repository and renamed my code repository to become my Personal GitHub Pages.\nSorting out syntax highlighting I work a lot with Powershell, and after enabling Syntax highlighting, it was clear that PaperMod\u0026rsquo;s included highlight.js did not include support for Powershell. It was also 2 years out of date, running version 10.2.1. I forked the repository, downloaded highlight.js version 11.6.0 with Powershell support and dropped it in place. I updated .gitmodules to point to my own fork of PaperMod, and forced an update of the submodule by running git submodule update --remote --merge\nSyntax highlighting is now working!\nNow time for comments My WordPress blog has comments, and while I don\u0026rsquo;t think they\u0026rsquo;re strictly necessary for a blog of this nature, it is nice to receive feedback from those who\u0026rsquo;ve been helped by what I\u0026rsquo;ve written, or indeed those who need a bit more help. I signed up for disqus, and integrated the comment HTML provided in to layouts\\partials\\comments.html in my PaperMod fork. I then enabled comments in the config.yml. I do have some reservations about Disqus, so perhaps may move to another platform in the future. Sadly at this stage I\u0026rsquo;ve not found a means to preserve the existing comments on my blog. Perhaps I\u0026rsquo;ll copy them in to the end of each article.\nMigrating content SchumacherFM has made a WordPress to Hugo exporter. I installed this on my WordPress instance and exported my posts. Expectedly, it doesn\u0026rsquo;t do a perfect job of pulling posts and converting them to Markdown, but it certainly does a good enough job to ease the process. Each post will need to be reviewed and edited in order to remove stray html tags, fix Unicode conversions and generally tidy up, but I\u0026rsquo;m very happy with the result.\nBack to comments, lets migrate those Disqus supports importing comments from WordPress. Excellent! I don\u0026rsquo;t have to forsake them after all. Unfortunately, importing via the WordPress plugin failed, so I exported my WordPress content to XML before going to import.disqus.com to import there. This worked. I am however moving the canonical URL of posts. My WordPress site used to have everything at the top level. EG: https://aidenwebb.com/how-to-fix-qnap-nas-web-gui-interface-timing-out-or-never-loading/. Under Hugo, I\u0026rsquo;m still going to have this URL as an alias, but it will direct to https://aidenwebb.com/posts/how-to-fix-qnap-nas-web-gui-interface-timing-out-or-never-loading/.\nTo map the URL changes, I\u0026rsquo;ve gone to my Disqus page, under the Moderation header, in the left-hand menu, I go to Migration tools. Here, I started the URL Mapper and downloaded a list of current posts, and created an equivalent redirected URL in the CSV before uploading it to the mapper.\n","permalink":"https://www.aidenwebb.com/posts/moving-my-blog-to-hugo-getting-started-with-hugo/","summary":"Introduction I recently came to the conclusion that I wasn\u0026rsquo;t posting on my blog nearly as much as I\u0026rsquo;d like to. My blog runs on WordPress, and I\u0026rsquo;ve felt for a while that the process of logging in, creating a post, fixing formatting in a WSYWGI editor and eventually posting was too much resistance when I commonly just write notes in plain text. So, why not just write posts in plain text and have something else do the work of turning that in to a post or a blog?","title":"Moving my blog to Hugo - Getting started with Hugo"},{"content":"The Problem You\u0026rsquo;ve set up Azure AD Connect or Azure AD Connect Cloud Sync, but some users haven\u0026rsquo;t sync\u0026rsquo;d correctly. Trying to force a new sync / Soft Link based on SMTP or UPN matching doesn\u0026rsquo;t work. These sync\u0026rsquo;d users may have created new Azure AD accounts, or may have failed to create an Azure AD account altogether. Your internal users UPN matches a domain configured in Azure AD.\nThe Cause The initial soft link matches on UPN or SMTP, but may fail if there are conflicting ProxyAddresses.\nThe Fix Linking On Premises accounts and Azure AD accounts involves matching the GUID of the On-Premises account with the ImmutableID property of the Azure AD account. This property can be written to using the Azure PowerShell module.\nWe need to manually apply the ImmutableID property to the Azure AD account.\nOpen an elevated PowerShell prompt on a system that is able to access Active Directory and the internet\nIn Preparation Install required modules\n1 2 Install-Module -Name AZ Add-WindowsCapability –online –Name Rsat.ActiveDirectory.DS-LDS.Tools~~~~0.0.1.0 Connect to Azure online\n1 Connect-MsolService Resolution steps Get the GUID of your on-premises user:\n1 $guid = (Get-ADUser -Identity \u0026#34;James.Bond\u0026#34;).ObjectGUID Convert the GUID to the ImmutableID used to hardlink in Azure AD\n1 $immutableid=[System.Convert]::ToBase64String($guid.tobytearray()) Check if a user in Azure AD is using this ImmutableID already\n1 Get-MsolUser | Where-Object {$_.immutableid -eq $immutableid} Either:\n⚠️DANGER⚠️: If the Azure AD user using the ImmutableID isn\u0026rsquo;t an account in use, and you have no need for it, delete it completely.\n1 2 Get-MsolUser | Where-Object {$_.immutableid -eq $immutableid} | Remove-MsolUser Get-MsolUser | Where-Object {$_.immutableid -eq $immutableid} | Remove-MsolUser -RemoveFromRecycleBin If the Azure AD user using the Immutable ID is an account that you use, and you don\u0026rsquo;t want to delete it, set its ImmutableID to Null\n1 Get-MsolUser | Where-Object {$_.immutableid -eq $immutableid} | Set-MsolUser -ImmutableId $null Find the UPN of the Azure AD user you want to Hard Link\nSet the ImmutablieID on the correct AD user\n1 Set-MsolUser -UserPrincipalName James.Bond@CorrectCloudUpnDomain.com -ImmutableId $immutableid ","permalink":"https://www.aidenwebb.com/posts/how-to-hard-link-azure-ad-connect-on-prem-users-to-azure-ad-office-365-accounts/","summary":"The Problem You\u0026rsquo;ve set up Azure AD Connect or Azure AD Connect Cloud Sync, but some users haven\u0026rsquo;t sync\u0026rsquo;d correctly. Trying to force a new sync / Soft Link based on SMTP or UPN matching doesn\u0026rsquo;t work. These sync\u0026rsquo;d users may have created new Azure AD accounts, or may have failed to create an Azure AD account altogether. Your internal users UPN matches a domain configured in Azure AD.\nThe Cause The initial soft link matches on UPN or SMTP, but may fail if there are conflicting ProxyAddresses.","title":"How to Hard Link Azure AD Connect On Prem Users to Azure AD Office 365 Accounts"},{"content":"The Problem You\u0026rsquo;re unable to activate a copy of Windows Server 2019 or 2022 Evaluation edition with your VLSC MAK key\nThe Cause Windows Server 2019 / 2022 Evaluation edition can only be activated with a retail key. This must happen before a Volume Licence Key can be used.\nThe Fix We need to use DISM to change the product version/edition\nOpen an elevated command prompt\nGet a list of available version upgrade paths by typing:\n1 DISM.exe /Online /Get-TargetEditions Then upgrade to the listed edition by typing:\n1 DISM /Online /Set-Edition:\u0026lt;TargetEdition\u0026gt; /ProductKey:\u0026lt;Product Key from Below Table\u0026gt; /AcceptEula EG: DISM /Online /Set-Edition:ServerDatacenterCor /ProductKey:XXXXX-XXXXX-XXXXX-XXXXX-XXXXX /AcceptEula\nServer Edition Product GVLK Windows Server 2022 Datacenter WX4NM-KYWYW-QJJR4-XV3QB-6VM33 Windows Server 2022 Datacenter Azure Edition NTBV8-9K7Q8-V27C6-M2BTV-KHMXV Windows Server 2022 Standard VDYBN-27WPP-V4HQT-9VMD4-VMK7H Windows Server 2019 Datacenter WMDGN-G9PQG-XVVXX-R3X43-63DFG Windows Server 2019 Standard N69G4-B89J2-4G8F4-WWYCC-J464C Windows Server 2019 Essentials WVDHN-86M7X-466P6-VHXV7-YY726 Windows Server 2019 Azure Core FDNH6-VW9RW-BXPJ7-4XTYG-239TB Windows Server 2019 Datacenter Semi-Annual Channel (v.1809) 6NMRW-2C8FM-D24W7-TQWMY-CWH2D Windows Server 2019 Standard Semi-Annual Channel (v.1809) N2KJX-J94YW-TQVFB-DG9YT-724CC Windows Server 2019 ARM64 GRFBW-QNDC4-6QBHG-CCK3B-2PR88 Windows Server 2016 Standard Semi-Annual Channel (v.1803) PTXN8-JFHJM-4WC78-MPCBR-9W4KR Windows Server 2016 Datacenter Semi-Annual Channel (v.1803) 2HXDN-KRXHB-GPYC7-YCKFJ-7FVDG Windows Server 2016 Datacenter Semi-Annual Channel (v.1709) 6Y6KB-N82V8-D8CQV-23MJW-BWTG6 Windows Server 2016 Standard Semi-Annual Channel (v.1709) DPCNP-XQFKJ-BJF7R-FRC8D-GF6G4 Windows Server 2016 ARM64 K9FYF-G6NCK-73M32-XMVPY-F9DRR Windows Server 2016 Datacenter CB7KF-BWN84-R7R2Y-793K2-8XDDG Windows Server 2016 Standard WC2BQ-8NRM3-FDDYY-2BFGV-KHKQY Windows Server 2016 Essentials JCKRF-N37P4-C2D82-9YXRT-4M63B Windows Server 2016 Cloud Storage QN4C6-GBJD2-FB422-GHWJK-GJG2R Windows Server 2016 Azure Core VP34G-4NPPG-79JTQ-864T4-R3MQX Reboot the system and enter your MAK key either via the GUI or by running the two commands\n1 2 slmgr.vbs /ipk \u0026lt;Your Product Key\u0026gt; slmgr.vbs /ato ","permalink":"https://www.aidenwebb.com/posts/how-to-fix-server-2019-activation-error-run-slui.exe-0x2a-0xc004f069/","summary":"The Problem You\u0026rsquo;re unable to activate a copy of Windows Server 2019 or 2022 Evaluation edition with your VLSC MAK key\nThe Cause Windows Server 2019 / 2022 Evaluation edition can only be activated with a retail key. This must happen before a Volume Licence Key can be used.\nThe Fix We need to use DISM to change the product version/edition\nOpen an elevated command prompt\nGet a list of available version upgrade paths by typing:","title":"How to Fix Server 2019 Activation Error: Run “slui.exe 0x2a 0xC004F069”"},{"content":"The Problem Veeam is failing to back up one of your Hyper-V VM\u0026rsquo;s and is throwing the error: VHDx:CVhdxDisk.InitialValidation: Invalid bitmap block (all bitmap block of fixed and dynamic disks must be in SB_BLOCK_NOT_PRESENT state) Agent failed to process method {VHDx.GetDiskInformation}\nThe Cause The error is telling us that Veeam\u0026rsquo;s VHDx InitialValidation function failed as the VHDx had blocks in an invalid state.\nAccording to Microsoft\u0026rsquo;s OpenSpecs Documentation for VHDx, the only valid Sector Bitmap Block state for fixed and dynamic disks is SB_BLOCK_NOT_PRESENT\nSector and Payload Bitmap blocks are used in the translation of VHD offset to a VHD file offset, and so is loosely analogous to traditional hard disk clusters.\nWe can therefore conclude that we are dealing with either VHDx corruption or file system cluster misallocation.\nThe Fix Dealing with File System Corruption Before we start, find the VM in Hyper-V Manager and delete/merge any checkpoints. Wait for the merge to complete before continuing.\nIf there are any checkpoints, the changes we make with chkdsk will only affect the differencing AVHDX file, and the VHDX file will remain corrupt.\nLog in to the VM that is failing to be backed up\nRun CMD as an Administrator and run mountvol to get a list of Volumes on the system, even those with no drive letter.\nFor each volume, run chkdsk \u0026quot;\\\\?\\Volume{VOLUMEID}\u0026quot; /f /r /x s to dismount the disk to fix errors on the and repair bad sectors. If repairing the system volume, a reboot will be necessary and the scan will run on startup. It\u0026rsquo;s vital that all volumes are scanned, not just those with a drive letter.\nIf chkdsk finds bad sectors, you will see this in the Chkdsk log under Stage 4 and 5.\nOnce chkdsk is complete on all drives, try running the backup again. If the SB_BLOCK_NOT_PRESENT error persists, try repairing the VHDx file as below\nRepair corrupt VHDx files The only way to truly \u0026ldquo;repair\u0026rdquo; a VHDX file is to create a new one. To do this we\u0026rsquo;re going to use Hyper-V Manager to convert the existing VHDx to a new one.\nFind the affected VM in Hyper-V manager\nShut down the system and delete / merge any checkpoints it has. Wait for the merge to complete before continuing\nGo into the VM settings and for each Virtual Hard Disk attacked go through the Edit Virtual Hard Disk Wizard\nClick Edit to open the wizard Under Choose Action, select Convert Choose VHDX as the disk format Choose your preferred Disk Type Choose a name and location for your new disk, keep a note of it. I recommend using the same path as the old disk and appending \u0026ldquo;_v2\u0026rdquo; before the extension Wait for disk conversion to complete Back in the VM settings, change the path to the new VHDX Once all disks are converted and the new disks are attached to the VM. Boot it back up, ensure it\u0026rsquo;s working and try running the backup again. It should now work\nOnce you\u0026rsquo;re satisfied that your VM is running smoothly on its new VHDX\u0026rsquo;s and is backing up successfully, archive or delete your old, corrupt VHDX files\n","permalink":"https://www.aidenwebb.com/posts/how-to-fix-sb_block_not_present-error-in-veeam/","summary":"The Problem Veeam is failing to back up one of your Hyper-V VM\u0026rsquo;s and is throwing the error: VHDx:CVhdxDisk.InitialValidation: Invalid bitmap block (all bitmap block of fixed and dynamic disks must be in SB_BLOCK_NOT_PRESENT state) Agent failed to process method {VHDx.GetDiskInformation}\nThe Cause The error is telling us that Veeam\u0026rsquo;s VHDx InitialValidation function failed as the VHDx had blocks in an invalid state.\nAccording to Microsoft\u0026rsquo;s OpenSpecs Documentation for VHDx, the only valid Sector Bitmap Block state for fixed and dynamic disks is SB_BLOCK_NOT_PRESENT","title":"How to fix SB_BLOCK_NOT_PRESENT error in Veeam"},{"content":"Introduction ITIL defines an incident as “an unplanned interruption to or quality reduction of an IT service”.\nIn order to minimise disruption caused by an incident and restore normal service as quickly as possible, it\u0026rsquo;s vital to have an efficient incident management process. Unfortunately, this is something a lot of IT teams get wrong.\nUnmanaged Incidents It\u0026rsquo;s 1 PM and your team has just started receiving calls from one of your users that the network drives are down. No-one can access anything or save anything and the business cannot function. You don\u0026rsquo;t know it yet but 4 separate people in your IT team are now trying everything they can to get the drives back up and running.\nJames is logging in to the file servers, he calls on previous experience and triggers a restart, hoping they\u0026rsquo;ll pop back up and be OK. They take a while to shutdown.\nKirsty tries pinging the server and gets no response. She starts looking at the firewalls and finds a rule that looks a bit funny. She changes it, thinking that traffic can no longer reach the file servers. The server now responds to ping but after a minute it stops responding again. Unknown to her, this rule was used for testing an FTP server before that IP was assigned to a file server. The file server is now exposed to the internet.\nRyan jumps in remembering a switch in the users\u0026rsquo; office was displaying some errors when he checked it yesterday. He hops in and sees some dropped packets on one interface. He thinks it might be a broadcast storm and disables the interface. Unbeknownst to him, this interface handles VOIP traffic.\nSam also checks the file servers and sees them waiting to shut down, so Sam forces a power-off thinking that they\u0026rsquo;ve hung and now they won\u0026rsquo;t boot at all.\nIt\u0026rsquo;s been 5 minutes. You don\u0026rsquo;t know it yet, but a firewall rule has changed, a switch port has been disabled, production servers have been rebooted, no-one has spoken to each other and now you\u0026rsquo;re getting a call from the VP of Sales telling you that all the phone lines are down in his office and no-one can access the network. He\u0026rsquo;s pissed and wants to know how on earth everything can collapse so quickly without warning.\nAfter some time, you manage to unravel everything, undo the changes to the firewall, the switch and restore the servers from a backup, but it takes a long time and was complicated by the additional changes. After re-enabling the switch rule, you\u0026rsquo;re not seeing any traffic flowing through the interface. You can\u0026rsquo;t seem to get it to detect any traffic and decide to reboot it. It works and 3 hours later and the incident is resolved. You come to the conclusion that maybe the VOIP port might be being used for non-VOIP traffic but you\u0026rsquo;re going to have to investigate that later. Right now, you\u0026rsquo;re being called into a meeting with the VP of Sales and the Managing Director to explain the situation. You\u0026rsquo;re not really sure if the firewall, switch, or file servers being down was the actual cause, but you know that rebooting the switch was the last thing you did before it started working.\nWhat went wrong? It\u0026rsquo;s easy to see that everyone in the above scenario was doing their job and working towards a solution, but at the same time, within minutes additional breaking changes have been introduced to the system.\nTunnel vision on a technical problem It\u0026rsquo;s not surprising that members of a technical IT team are keen to jump in and fix a technical problem, however, none took the time to gather information and acquire a broader picture of the error at hand.\nPoor communication Because everyone was too busy rushing to resolve a technical problem, no-one took the time to communicate with each other about who was doing what. Customers did not know what to expect, the VP is angry, members of the team are blaming each other for shutting down the servers, enabling firewall rules and disabling switch ports.\nBreaking Changes Each member of the team made changes to the system without consulting each other or following a Change Management Process. It may be there wasn\u0026rsquo;t one in place. However, despite good intentions from each member, these breaking changes made a bad situation worse.\nAn unclean shutdown of a production file server causing some system corruption requiring recovery A port was opened on the firewall exposing the file server to the internet which could have caused a security incident A switch port was disabled which blocked VOIP traffic in the office. What can we do better? - Manage the incident It\u0026rsquo;s 1 PM. James, Kirsty, Ryan and Sam each finish a call with someone at the office, and each of their users are unable to access the network drives. James and Kirsty each think that this is big enough to report to you, and do so. You ask if anyone else has seen the issue and Ryan and Sam each flag to you that they have spoken to users with the same issue.\nYou get to work, each of your team members gives their ideas on where the problem might be. You ask each to investigate, test functionality and report back on what they find.\nJames logs in to the file servers, checks the services are running and the health of the shares. He tests the shares from another system in the data centre. All are fine, he reports. You ask him to test from multiple different offices to determine if there\u0026rsquo;s a pattern.\nKirsty tries pinging the server and gets no response. She checks the firewall and finds a suspicious rule. She notes down the configuration and reports back to you. You note it down as a potential cause to investigate shortly.\nRyan checks the switch at the office and sees it dropping packets. He flags this to you and you note this as another potential cause.\nSam writes an email to send to the users at the office, including the VP of Sales, informing them that you know about and are working towards resolving their network drive issue.\nKirsty and you investigate the Firewall rule while Ryan investigates further on the switch. You decide the firewall rule is unlikely to be the cause, as it is disabled, and it\u0026rsquo;s configured to allow FTP traffic, not SMB. You acknowledge that the firewall rule may need addressing separately and ask Kirsty to log a ticket for it.\nRyan reports he doesn\u0026rsquo;t know why the switch is dropping packets, but the CPU is running at 100%.\nJames comes back to you and confirms that all other offices besides the one that reported the problem are able to connect to the network drives.\nYou ask Sam to contact users at the office to test their internet connectivity as well as VOIP quality. He comes back to you saying the internet is slow and the VOIP quality is poor.\nAfter further investigating you discover the network switch is faulty. You reboot it and it comes back up. Phew! 30 minutes after the outage, the issue is resolved.\nSam contacts users to confirm that they are now able to access the network shares and you raise a business case for a replacement switch.\nWhat went right? The managed situation was a far more efficient resolution that managed user expectations and resolved the incident cleanly without introducing further problems. What\u0026rsquo;s more, you were able to test and verify components in isolation in order to narrow down on the root cause.\nBroad vision and teamwork Because some members of the team recognised that the outage wasn\u0026rsquo;t isolated to a single user, and let you know, you were able to take command and lead the team towards resolution. You were able to collectively take stock of what was working before jumping to conclusions.\nGood communication Not only did your team communicate with you, but Sam took the role of keeping the users updated. As a result, the VP of Sales is informed and, while a little grumpy at some lost time, is pleased that the issue was resolved and you\u0026rsquo;re able to prevent a recurrence. The users are happy because rather than constantly refreshing the network share to check if it\u0026rsquo;s working yet, they were able to get on with other tasks or take a break safe in the knowledge that you\u0026rsquo;d let them know when the issue was resolved. The team are pleased with each other and feel they all made a meaningful contribution towards the resolution of the incident.\nNo Breaking Changes Because we all took account of what was working, what was broken, and where, we were able to isolate the incident to a single piece of infrastructure. We were also able to gather and preserve data that we can use as evidence for our business case to replace the switch. We have a good amount of information about where the problem did and not occur, and which components were faulty.\nIn Summary With a strong incident management strategy, we\u0026rsquo;re able to reduce the mean time to resolution (MTTR) of incidents, as well as reduce the amount of stress both our users and IT team are subject to when things go wrong. Any company that values reliability and efficiency would benefit from planning their incident response strategy in advance.\nPrepare: Build and document your incident management strategy and train staff in its implementation.\nInvestigate: Confirm functionality of components to narrow down the cause before making any changes\nPrioritise: Restore service as soon as possible, while preserving evidence and logs for deeper root cause analysis\nSeparate: Spread the workload, giving each member of the incident management team a specific role. Vital roles are Manager, Operations, Comms and Planning.\nManager has the job of holding the high-level state of the incident and orchestrating the response. Operations has the job of investigating and implementing resolution steps to the incident. Comms has the job of communicating with users and stakeholders, providing updates and flagging new information. Support has the job of supporting the other roles by logging additional tickets for things to check in on later, tracking changes to the system, arranging handovers and regular coffee. Trust: Allow your IT team autonomy within their role in the incident management process. Reducing crossover prevents people from feeling overwhelmed!\nManage Emotion: Be aware of the emotional state of you, your staff, and your users when managing an incident. If people are starting to feel panicked and overwhelmed, they\u0026rsquo;re more likely to make mistakes. Take high emotions as a signal to solicit further help.\nReview: After the incident, review with your team and users to determine if there\u0026rsquo;s anything you could have done better. Continually improving the process over time and tailoring it to your culture and organisation is vital to the continued success of the process.\nFootnotes This incident management strategy is adapted from FEMA\u0026rsquo;s National Incident Management System.\nOn Page 52: Communications management.\nManager corresponds to Strategic communication Operations corresponds to Tactical communication Support corresponds to\u0026hellip; well, Support Comms corresponds to Public communication ","permalink":"https://www.aidenwebb.com/posts/traps-and-dangers-of-unmanaged-incidents-and-how-to-solve-them/","summary":"Introduction ITIL defines an incident as “an unplanned interruption to or quality reduction of an IT service”.\nIn order to minimise disruption caused by an incident and restore normal service as quickly as possible, it\u0026rsquo;s vital to have an efficient incident management process. Unfortunately, this is something a lot of IT teams get wrong.\nUnmanaged Incidents It\u0026rsquo;s 1 PM and your team has just started receiving calls from one of your users that the network drives are down.","title":"Traps and Dangers of Unmanaged Incidents and How to Solve Them"},{"content":"Check Task Manager The first, simplest option to check is to open task manager. Click the performance tab Check if Virtualisation is Enabled If Virtualisation is not Enabled, this could be due to it being disabled in the BIOS. Before enabling it, check if your processor is compatible.\nCheck Processor Compatibility Identify your Processor Press the Windows Key Type \u0026ldquo;System Information\u0026rdquo; in the search box Make a note of your processor make and model Check Product Specs - Intel: If your processor is Intel, go to the Intel Product Specification Page and look up your processor model and open the specification page. Under the \u0026ldquo;Advanced Technologies\u0026rdquo; heading, if Virtualisation is supported, Intel Virtualization Technology (VT-x) will say yes Check Product Specs - AMD: If your processor is AMD, go to the AMD Product Specification Page and look up your processor model and open the specification page. If the Launch Date is any time after 2007, your CPU supports virtualisation. Unlike Intel, AMD don\u0026rsquo;t reserve Virtualisation technologies for only some of their processors. ","permalink":"https://www.aidenwebb.com/posts/how-to-check-if-your-cpu-supports-virtualisation/","summary":"Check Task Manager The first, simplest option to check is to open task manager. Click the performance tab Check if Virtualisation is Enabled If Virtualisation is not Enabled, this could be due to it being disabled in the BIOS. Before enabling it, check if your processor is compatible.\nCheck Processor Compatibility Identify your Processor Press the Windows Key Type \u0026ldquo;System Information\u0026rdquo; in the search box Make a note of your processor make and model Check Product Specs - Intel: If your processor is Intel, go to the Intel Product Specification Page and look up your processor model and open the specification page.","title":"How to check if your CPU supports Virtualisation"},{"content":"The Problem You\u0026rsquo;re trying to connect to your NAS\u0026rsquo;s web interface but it\u0026rsquo;s just spinning forever and not actually loading.\nThe Cause The cause can be a number of things, but it boils down to an issue with the http service or proxy service on the QNAP.\nSometimes a configuration problem will cause the service to behave badly. A firmware update may cause a mismatch between the config file and the service being run.\nThe Fix I\u0026rsquo;m assuming at this point that you\u0026rsquo;ve tried rebooting the NAS and that hasn\u0026rsquo;t resolved the issue. Here are some other things you can try.\nReset the Admin account config Download, install and run WinSCP In WinSCP, set the option to show hidden files (keyboard shortcut Ctrl-Alt-H or Click Options \u0026gt; Preferences \u0026gt; Panels and ensure that \u0026ldquo;Show hidden files\u0026rdquo; is checked, then click OK ) Connect to the IP of your QNAP NAS as Admin Click Open Directory and enter: /etc/config/.qos_config/users/admin/ Download the config and .qtoken files to your local machine as a backup Delete the config and .qtoken files on the QNAP Click Commands \u0026gt; Open Terminal Type \u0026ldquo;reboot\u0026rdquo; and click execute to reboot the NAS Note it may take a long time for the NAS to reboot. Leave it to do what it needs to do for at least half an hour. Periodically attempt to reconnect to WinSCP / the Web page, or use QFinder to determine when the QNAP is back online.\nRestart the HTTP server / amend configuration If the above does not work, you may have a different problem, not currently covered in this guide. It\u0026rsquo;s worth restarting the http service and confirming both start OK. Note all commands here are case sensitive. Slashes (\\) and backslashes (/) are also not interchangeable as they are in a Windows environment.\nDownload and run Putty\nConnect to your QNAP via SSH and log in as Admin\nNavigate to the init.d directory\n1 cd /etc/init.d/ List all the http shell scripts, you should see both \u0026ldquo;Qthttpd.sh\u0026rdquo; (Web Server) and \u0026ldquo;thttpd.sh\u0026rdquo; (Apache Proxy)\n1 ls -1 | grep \u0026#39;http\u0026#39; Restart Qthttpd, confirm that shutdown and start both return OK.\n1 ./Qthttpd.sh restart Restart thttpd, confirm that shutdown and start both return OK\n1 ./thttpd.sh restart If the Apache proxy does not start:- Get the Web Access Port config, you should see \u0026ldquo;8080\u0026rdquo; being displayed. If it does not, go to Step 2.\n1 /sbin/getcfg SYSTEM \u0026#34;Web Access Port\u0026#34; Set the Web Access Port to 8080 as should be default\n1 /sbin/setcfg SYSTEM \u0026#34;Web Access Port\u0026#34; 8080 Restart the thttpd service and apache proxy\n1 /etc/init.d/thttpd.sh restart ","permalink":"https://www.aidenwebb.com/posts/how-to-fix-qnap-nas-web-gui-interface-timing-out-or-never-loading/","summary":"The Problem You\u0026rsquo;re trying to connect to your NAS\u0026rsquo;s web interface but it\u0026rsquo;s just spinning forever and not actually loading.\nThe Cause The cause can be a number of things, but it boils down to an issue with the http service or proxy service on the QNAP.\nSometimes a configuration problem will cause the service to behave badly. A firmware update may cause a mismatch between the config file and the service being run.","title":"How to fix QNAP NAS web GUI interface timing out or never loading"},{"content":"I\u0026rsquo;ve been asked why the Advanced Permissions dialogue on NTFS folders lists \u0026ldquo;Traverse folder / execute file\u0026rdquo; as one single permission.\nOn the surface it seems counterintuitive that you\u0026rsquo;d allow a user to navigate through a folder, or execute its contents.\nThere\u0026rsquo;s no official Microsoft documentation on the design decisions, however, from a filesystem perspective, entering a folder is the same as executing or running it. The same is true of 3 classic Unix filesystem flags and permissions, where the \u0026ldquo;X\u0026rdquo; flag allows both directory traversal and file execution, while \u0026ldquo;R\u0026rdquo; allows reading and \u0026ldquo;W\u0026rdquo; allows writing.\n","permalink":"https://www.aidenwebb.com/posts/why-traverse-folder-and-execute-file-is-a-combined-ntfs-permission/","summary":"I\u0026rsquo;ve been asked why the Advanced Permissions dialogue on NTFS folders lists \u0026ldquo;Traverse folder / execute file\u0026rdquo; as one single permission.\nOn the surface it seems counterintuitive that you\u0026rsquo;d allow a user to navigate through a folder, or execute its contents.\nThere\u0026rsquo;s no official Microsoft documentation on the design decisions, however, from a filesystem perspective, entering a folder is the same as executing or running it. The same is true of 3 classic Unix filesystem flags and permissions, where the \u0026ldquo;X\u0026rdquo; flag allows both directory traversal and file execution, while \u0026ldquo;R\u0026rdquo; allows reading and \u0026ldquo;W\u0026rdquo; allows writing.","title":"Why “traverse folder” and “execute file” is a combined NTFS permission"},{"content":"If you\u0026rsquo;re working on Windows Server Core or remotely on another computer and don\u0026rsquo;t have access to the Windows GUI, you might have trouble disabling a faulty or unwanted plug-and-play device. Thankfully PowerShell makes it easy to get, enable and disable devices in Device Manager using Get-PnpDevice, Enable-PnpDevice and Disable-PnpDevice\nHow to query devices 1 2 3 4 5 6 7 Get-PnpDevice # Get\u0026#39;s all PNP Devices Get-PnpDevice -PresentOnly # Gets all PNP Devices currently attached or physically present in the system Get-PnpDevice -FriendlyName \u0026#34;*Ethernet*\u0026#34; # Gets all PNP Devices with a name containing \u0026#34;Ethernet\u0026#34; Get-PnpDevice -Status ERROR # Gets all PNP Devices in an errored states How to enable or disable devices To enable disable a device, simply pipe the output of Get-PnpDevice to Disable-PnpDevice or Enable-PnpDevice. Please be sure your Get-PnpDevice command is targeting the correct device before piping to avoid accidentally disabling devices you\u0026rsquo;d rather keep enabled!\n1 2 3 Get-PnpDevice -FriendlyName \u0026#34;*Ethernet*\u0026#34; | Disable-PnpDevice # Disables all PNP Devices with a name containing \u0026#34;Ethernet\u0026#34; Get-PnpDevice -FriendlyName \u0026#34;*Ethernet*\u0026#34; | Enable-PnpDevice # Enables all PNP Devices with a name containing \u0026#34;Ethernet\u0026#34; You could also output the instance ID to a variable for use later if you\u0026rsquo;d rather\n1 2 $DeviceID = Get-PnPDevice -FriendlyName \u0026#34;Intel(R) Ethernet Connection I217-V\u0026#34; | Select-Object InstanceID Disable-PnpDevice -InstanceID $DeviceID Or\n1 2 $DeviceID = (Get-PnpDevice -FriendlyName \u0026#34;Intel(R) Ethernet Connection I217-V\u0026#34;).InstanceID Disable-PnpDevice -InstanceID $DeviceID ","permalink":"https://www.aidenwebb.com/posts/how-to-enable/disable-hardware-devices-using-windows-powershell/","summary":"If you\u0026rsquo;re working on Windows Server Core or remotely on another computer and don\u0026rsquo;t have access to the Windows GUI, you might have trouble disabling a faulty or unwanted plug-and-play device. Thankfully PowerShell makes it easy to get, enable and disable devices in Device Manager using Get-PnpDevice, Enable-PnpDevice and Disable-PnpDevice\nHow to query devices 1 2 3 4 5 6 7 Get-PnpDevice # Get\u0026#39;s all PNP Devices Get-PnpDevice -PresentOnly # Gets all PNP Devices currently attached or physically present in the system Get-PnpDevice -FriendlyName \u0026#34;*Ethernet*\u0026#34; # Gets all PNP Devices with a name containing \u0026#34;Ethernet\u0026#34; Get-PnpDevice -Status ERROR # Gets all PNP Devices in an errored states How to enable or disable devices To enable disable a device, simply pipe the output of Get-PnpDevice to Disable-PnpDevice or Enable-PnpDevice.","title":"How to enable/disable hardware devices using Windows Powershell"},{"content":"The proxy address is already being used by the proxy addresses of another mailbox\nWhy can\u0026rsquo;t I create a mailbox at account@domain2.com if one already exists at account@domain1.com\nThe Problem So, you have two (or more) domains associated with your Office 365 Exchange account. When you try to create a shared mailbox on one domain, you encounter an error stating the proxy address is already being used.\nFor example You have two domains, lets call them domain1.com and domain2.com You\u0026rsquo;re trying to create a shared mailbox on domain2.com and you\u0026rsquo;re hitting an error. The message reads:\nThe proxy address \u0026ldquo;SMTP:name@domain.com\u0026rdquo; is already being used by the proxy addresses or LegacyExchangeDN. Please choose another proxy address.\u0026quot;\nThe Cause This issue occurs because the Shared Mailbox we\u0026rsquo;re trying to create is automatically assigned a UserPrincipalName on the default domain for the organisation, no matter which domain we try to create it on.\nFor example.\nYou have a user, shared or resource mailbox already in existence on domain1.com with an alias of finance@domain1.com When you try to create the finance@domain2.com mailbox, Office365 tries to assign the UserPrincipalName as finance@domain1.com, this is already in use so O365 throws the error that we\u0026rsquo;re seeing. The Fix Connect to Office365 / Exchange as an admin via PowerShell\n1 2 3 $UserCredential = Get-Credential $Session = New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $UserCredential -Authentication Basic -AllowRedirection Import-PSSession $Session -DisableNameChecking Remove the alias from the existing mailbox (don\u0026rsquo;t worry, we\u0026rsquo;ll add it back shortly!)\nNOTE: If the conflicting alias is the default SMTP for the mailbox, you\u0026rsquo;ll need to create a new temporary default SMTP alias before removing the conflicting one\n1 Set-Mailbox account@domain1.com -EmailAddresses @{remove=\u0026#34;finance@domain1.com\u0026#34;} Create the shared mailbox you want to create on domain2.com\n1 New-Mailbox -Name finance@domain2.com -Shared The value for \u0026ldquo;MicrosoftOnlineServicesID\u0026rdquo; is the value of the Mailbox Property \u0026ldquo;WindowsLiveID\u0026rdquo; and this defaults to your default domain, as explained in The Cause – https://msdn.microsoft.com/en-us/library/ee423637(v=exchsrvcs.149).aspx\nWe want to change this to our secondary domain to enable us to delete the default primary domain smtp alias.\nIgnore the warning that appears after you run the command.\n1 2 Set-Mailbox finance@domain2.com -MicrosoftOnlineServicesID finance@domain2.com WARNING: UserPrincipalName \u0026#34;finance@domain1.com\u0026#34; should be same as WindowsLiveID \u0026#34;finance@domain2.com\u0026#34;, UserPrincipalName should remain as\u0026#34;finance@domain2.com\u0026#34;. Remove the default smtp address from our new mailbox\n1 Set-Mailbox finance@domain2.com -EmailAddresses @{remove=\u0026#34;finance@domain1.com\u0026#34;} Confirm that the removal was successful\n1 2 3 4 5 6 Get-Recipient finance@domain2.com | select name, emailaddresses Name EmailAddresses ---- -------------- finance@domain1.com {SMTP:finance@domain1.com} Add the domain1.com alias back to the email address.\n1 Set-Mailbox account@domain1.com -EmailAddresses @{add=\u0026#34;finance@domain1.com\u0026#34;} ","permalink":"https://www.aidenwebb.com/posts/how-to-fix-conflicting-proxy-addresses-in-o365-when-creating-a-mailbox/","summary":"The proxy address is already being used by the proxy addresses of another mailbox\nWhy can\u0026rsquo;t I create a mailbox at account@domain2.com if one already exists at account@domain1.com\nThe Problem So, you have two (or more) domains associated with your Office 365 Exchange account. When you try to create a shared mailbox on one domain, you encounter an error stating the proxy address is already being used.\nFor example You have two domains, lets call them domain1.","title":"How to fix conflicting proxy addresses in O365 when creating a mailbox"},{"content":"I am a Systems and Infrastructure Architect based in Bournemouth, UK\nI\u0026rsquo;m an avid learner and love a challenge.\nI started this blog as a creative outlet at a time where I most needed to organise my thoughts. Here you\u0026rsquo;ll find helpful tips, introspection and plenty of shenanigans.\nI\u0026hellip;\nWork full time at John Smith and Sons Group as an IT Systems Architect, Engineer and Admin.\nFreelance as a web designer and manage web hosting at Rootwire.\nAnd I run a circus and entertainments company, Steamship Circus!\nPhoto credit Will Tudor Photography. Go check him out!\n","permalink":"https://www.aidenwebb.com/about/","summary":"About Me","title":"About Me"},{"content":"The comment section can be a great place for interaction with readers, writers and even for spawning stimulating conversation – it can be a great place for all of us! To ensure that you have a good time over here at MSPU, please make sure to stick to the following guidelines:\nBe polite – don’t be rude to anyone and respect others. If something you would say would get you bottled on the head offline, please don’t say it here. Remember there is a person behind the screen and that your words affect people. Don’t troll. We appreciate and welcome criticism towards writers here, but comments that add no value to the discussion or that are merely insulting would be deleted without exception. Spam? Goodbye. We understand that you may make thousands of dollars working from home, however, we are not interested. Please refrain from posting or we’ll give you a hand and show both you and your post the door. To put it in a simple sentence, our guidelines boil down to “Don’t be a dick”. If you don’t follow any of these guidelines, not only will our moderators remove the comment but we may also ban you from participating in the discussions.\nIf you find any comments which violate our guidelines, please make sure to ‘flag’ or ‘mark as spam’ – our moderators highly appreciate your support!\nHappy commenting!\n","permalink":"https://www.aidenwebb.com/comment-policy/","summary":"comment policy","title":"Comment Policy"}]